{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6abd520d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Create dataset and look at the first item\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     ds \u001b[38;5;241m=\u001b[39m EEGDataset(data_root, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(ds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m items\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\\\Users\\\\evanc\\\\Documents\\\\Data_Science_Programs\\\\eeg_ml\\\\dat_dataset_4\\\\date_loader.py:53\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, data_dir, split)\u001b[0m\n\u001b[0;32m     49\u001b[0m file_name \u001b[38;5;241m=\u001b[39m raw_file_path\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m     51\u001b[0m log_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing_epochs.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(log_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m log_file:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# Log subject name only once\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subject_logged:\n\u001b[0;32m     56\u001b[0m         log_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing files for subject: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<frozen codecs>:186\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Simple EEG dataset peek (absolute import path)\n",
    "import os\n",
    "import sys\n",
    "from importlib import util\n",
    "\n",
    "# Absolute path to the data loader file\n",
    "loader_path = r\"c:\\\\Users\\\\evanc\\\\Documents\\\\Data_Science_Programs\\\\eeg_ml\\\\dat_dataset_4\\\\date_loader.py\"\n",
    "\n",
    "# Dynamically import the DataLoader class from the absolute path\n",
    "spec = util.spec_from_file_location(\"eeg_data_loader\", loader_path)\n",
    "mod = util.module_from_spec(spec)\n",
    "spec.loader.exec_module(mod)\n",
    "EEGDataset = getattr(mod, \"DataLoader\")\n",
    "\n",
    "# Absolute dataset root (contains 'raw' and 'clean' subfolders)\n",
    "data_root = r\"c:\\\\Users\\\\evanc\\\\Documents\\\\Data_Science_Programs\\\\eeg_ml\\\\dat_dataset_4\"\n",
    "\n",
    "# Create dataset and look at the first item\n",
    "try:\n",
    "    ds = EEGDataset(data_root, split='training_epochs')\n",
    "    setattr(ds, 'transform', None)\n",
    "    print(f\"Dataset length: {len(ds)} items\")\n",
    "    if len(ds) > 0:\n",
    "        sample = ds[0]\n",
    "        raw = sample['raw']\n",
    "        clean = sample['clean']\n",
    "        print(\"raw:\", type(raw), tuple(raw.size()) if hasattr(raw, 'size') else None)\n",
    "        print(\"clean:\", type(clean), tuple(clean.size()) if hasattr(clean, 'size') else None)\n",
    "    else:\n",
    "        print(\"Dataset is empty.\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating/reading dataset:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146324c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the size of the first tensor in EEGDataset\n",
    "import torch\n",
    "\n",
    "if 'ds' not in globals():\n",
    "    print(\"Dataset 'ds' not found. Please run cell 1 first to create it.\")\n",
    "else:\n",
    "    try:\n",
    "        n = len(ds)\n",
    "        print(f\"Dataset length: {n}\")\n",
    "        if n == 0:\n",
    "            print(\"Dataset is empty.\")\n",
    "        else:\n",
    "            sample = ds[0]\n",
    "            # Choose the \"first\" tensor: prefer 'raw' if present, else first value\n",
    "            first_tensor = None\n",
    "            if isinstance(sample, dict):\n",
    "                if 'raw' in sample:\n",
    "                    first_tensor = sample['raw']\n",
    "                else:\n",
    "                    try:\n",
    "                        first_tensor = next(iter(sample.values()))\n",
    "                    except Exception:\n",
    "                        first_tensor = None\n",
    "            elif isinstance(sample, (list, tuple)) and len(sample) > 0:\n",
    "                first_tensor = sample[0]\n",
    "            else:\n",
    "                first_tensor = sample\n",
    "\n",
    "            if hasattr(first_tensor, 'size'):\n",
    "                print(\"First tensor size:\", tuple(first_tensor.size()))\n",
    "                print(\"dtype:\", getattr(first_tensor, 'dtype', None), \"device:\", getattr(first_tensor, 'device', None))\n",
    "            else:\n",
    "                print(\"First item is not a tensor:\", type(first_tensor))\n",
    "    except Exception as e:\n",
    "        print(\"Error accessing dataset:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
